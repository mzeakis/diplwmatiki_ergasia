{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data.....ornah\n",
      "\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "key_training_data = []\n",
    "\n",
    "class Labeling():        \n",
    "        \n",
    "    def make_training_data():\n",
    "        \n",
    "        \n",
    "        keys = ['C','C#','Db','D','D#','Eb','E','F','F#','Gb','G','G#','Ab','A','A#','Bb','B']\n",
    "        keyIndex = [0, 1, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 10, 11]\n",
    "        keys_counters= [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        path = \"C:/outs/spects4096\"\n",
    "        #path = \"C:/outs/square4096\"\n",
    "        os.chdir(path)\n",
    "        spectrograms = os.listdir()\n",
    "        key_count = [0] * 24\n",
    "        annotations = open(\"C:/outs/shiftedAnnotations4096.txt\", \"r\")\n",
    "        #annotations = open(\"C:/outs/square4096.txt\", \"r\")\n",
    "        while True: \n",
    "            line = annotations.readline()\n",
    "            if not line:\n",
    "                break;\n",
    "            \n",
    "            \n",
    "            file, key, chord = line.split(' ', 2)\n",
    "            key = key.strip()\n",
    "            chord = chord.strip()\n",
    "            file = file + \".LOFI.png\"\n",
    "            spect_path = os.path.join(path, file)\n",
    "            spect_path = cv2.imread(spect_path)\n",
    "            #spect_path = cv2.resize(spect_path, (224, 224))  \n",
    "            #spect_path = cv2.imread(spect_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            \n",
    "            if spect_path is None :\n",
    "                continue;\n",
    "                \n",
    "            for j,i in enumerate(keys):\n",
    "                \n",
    "                temp = keyIndex[j]\n",
    "                if keys_counters[temp] > 200 : \n",
    "                    continue;\n",
    "                \n",
    "                if key == i:\n",
    "                    key_training_data.append([np.array(spect_path)/255, torch.LongTensor([keyIndex[j]])])\n",
    "                    keys_counters[temp] += 1\n",
    "           \n",
    "            #print(file)\n",
    "            #for j,i in enumerate(chords):\n",
    "                #if (chordsCounters[0] > 6500) & (chord == 'minor'):\n",
    "                    #continue;\n",
    "                    \n",
    "                #if (chordsCounters[1] > 2500) :\n",
    "                    #continue;\n",
    "                    \n",
    "                #if chord == i:\n",
    "                   #chord_training_data.append([np.array(spect_path)/255, torch.LongTensor([chordsIndex[j]])])\n",
    "                   # chordsCounters[j] += 1\n",
    "\n",
    "        \n",
    "        #np.random.shuffle(key_training_data)\n",
    "        np.random.shuffle(key_training_data)\n",
    "        print(\"saving data.....ornah\\n\")\n",
    "        #np.save(\"chord_training_data.npy\", chord_training_data)\n",
    "            \n",
    "        print(keys_counters)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    Labeling.make_training_data()\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyAlexNet(\n",
       "  (pretrained): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (my_new_layers): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "pretrained = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "ct = 0 \n",
    "for child in pretrained.children():\n",
    "    ct += 1 \n",
    "    if ct < 30:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False \n",
    "\n",
    "class MyAlexNet(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(MyAlexNet, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.my_new_layers = nn.Sequential(nn.Linear(1000, 100),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(100, 12))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = self.my_new_layers(x)\n",
    "        return x\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    my_extended_model = MyAlexNet(my_pretrained_model=pretrained).to(device)\n",
    "\n",
    "    \n",
    "my_extended_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer komple \n"
     ]
    }
   ],
   "source": [
    "#SETTING OPTIMIZER\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(my_extended_model.parameters(), lr=0.001, momentum = 0.9, weight_decay = 0.0001) \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    loss_function = loss_function.to(device)\n",
    "\n",
    "print(\"optimizer komple \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**data loader ftw**\n",
      "---- Starting new epoch ----\n",
      "Epoch: 0. Loss: 2.4797537326812744 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 1. Loss: 2.446108341217041 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 2. Loss: 2.4826271533966064 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 3. Loss: 2.472019910812378 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 4. Loss: 2.4806265830993652 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  5.833333333333333\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 5. Loss: 2.499516248703003 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 6. Loss: 2.468791961669922 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 7. Loss: 2.4821276664733887 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 8. Loss: 2.453643321990967 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 9. Loss: 2.4466476440429688 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.916666666666666\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 10. Loss: 2.4677200317382812 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 11. Loss: 2.4778237342834473 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 12. Loss: 2.452038288116455 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 13. Loss: 2.4805989265441895 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 14. Loss: 2.4851038455963135 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.083333333333333\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 15. Loss: 2.477351188659668 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 16. Loss: 2.499994993209839 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 17. Loss: 2.46244478225708 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 18. Loss: 2.4929826259613037 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 19. Loss: 2.474721670150757 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  8.75\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 20. Loss: 2.477299690246582 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 21. Loss: 2.4862544536590576 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 22. Loss: 2.5146970748901367 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 23. Loss: 2.5406792163848877 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 24. Loss: 2.4373836517333984 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  9.583333333333334\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 25. Loss: 2.4796245098114014 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 26. Loss: 2.436086654663086 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 27. Loss: 2.4815287590026855 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 28. Loss: 2.483144760131836 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 29. Loss: 2.408294439315796 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.083333333333333\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 30. Loss: 2.492429494857788 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 31. Loss: 2.4549639225006104 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 32. Loss: 2.4604885578155518 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 33. Loss: 2.4260733127593994 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 34. Loss: 2.406493663787842 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  5.416666666666667\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 35. Loss: 2.476419448852539 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 36. Loss: 2.435603141784668 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 37. Loss: 2.480508804321289 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 38. Loss: 2.5114243030548096 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 39. Loss: 2.5631706714630127 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.5\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 40. Loss: 2.4452390670776367 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 41. Loss: 2.405906915664673 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 42. Loss: 2.403980016708374 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 43. Loss: 2.436016798019409 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 44. Loss: 2.43805193901062 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.916666666666666\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 45. Loss: 2.4387118816375732 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 46. Loss: 2.467576503753662 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 47. Loss: 2.4949750900268555 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 48. Loss: 2.3750178813934326 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 49. Loss: 2.4311959743499756 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  6.666666666666667\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 50. Loss: 2.532140016555786 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 51. Loss: 2.4601006507873535 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 52. Loss: 2.5455894470214844 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 53. Loss: 2.456948757171631 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 54. Loss: 2.4025721549987793 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  6.25\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 55. Loss: 2.4645025730133057 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 56. Loss: 2.4664971828460693 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 57. Loss: 2.5108838081359863 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 58. Loss: 2.440890312194824 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 59. Loss: 2.4817466735839844 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.916666666666666\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 60. Loss: 2.347515821456909 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 61. Loss: 2.386915683746338 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 62. Loss: 2.4935357570648193 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 63. Loss: 2.415980577468872 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 64. Loss: 2.457399606704712 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  6.25\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 65. Loss: 2.460855484008789 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 66. Loss: 2.405406951904297 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 67. Loss: 2.402050018310547 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 68. Loss: 2.3859620094299316 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 69. Loss: 2.5080275535583496 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.916666666666666\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 70. Loss: 2.3510894775390625 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 71. Loss: 2.447807788848877 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 72. Loss: 2.4625282287597656 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 73. Loss: 2.5049679279327393 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 74. Loss: 2.3929247856140137 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  5.833333333333333\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 75. Loss: 2.4655346870422363 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 76. Loss: 2.400935173034668 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 77. Loss: 2.415173053741455 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 78. Loss: 2.509460210800171 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 79. Loss: 2.4735889434814453 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  6.666666666666667\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 80. Loss: 2.396559238433838 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 81. Loss: 2.3569345474243164 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 82. Loss: 2.3773651123046875 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 83. Loss: 2.450637102127075 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 84. Loss: 2.418525457382202 \n",
      "\n",
      "\n",
      "``Starting mini Testing``\n",
      "Accuracy:  7.083333333333333\n",
      "\n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 85. Loss: 2.4129714965820312 \n",
      "\n",
      "---- Starting new epoch ----\n",
      "Epoch: 86. Loss: 2.4852728843688965 \n",
      "\n",
      "---- Starting new epoch ----\n"
     ]
    }
   ],
   "source": [
    "#TRAINING KEY NEURAL NETWORK\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_size = int(len(key_training_data)*0.1)\n",
    "\n",
    "print_flag = True\n",
    "correct, total = 0, 0\n",
    "batchSize = 16\n",
    "training_data = key_training_data[:len(key_training_data)-val_size]\n",
    "test_data = key_training_data[-val_size:]\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size = batchSize, shuffle=True, drop_last=True)\n",
    "train_dataloader = DataLoader(training_data, batch_size=batchSize , shuffle=True, pin_memory=True, drop_last=True)\n",
    "\n",
    "print(\"**data loader ftw**\")\n",
    "\n",
    "my_extended_model.train()\n",
    "num_epochs = 134\n",
    "\n",
    "#test_counter = 0\n",
    "for epoch in range(0, num_epochs):\n",
    "    print(\"---- Starting new epoch ----\")\n",
    "    #running_loss = 0.0\n",
    "    #loss_values = [] \n",
    "    \n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        \n",
    "        #test_counter += 1\n",
    "        inputs = data[0].view(-1,3,105,600)\n",
    "        targets = data[1]\n",
    "        inputs = inputs.float()\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_extended_model(inputs)\n",
    "        \n",
    "        \n",
    "        targets = targets.view(len(data[1]))\n",
    "        \n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (((epoch+1) % 5) == 0):\n",
    "        \n",
    "        print(f\"Epoch: {epoch}. Loss: {loss} \")\n",
    "        print_flag = False\n",
    "        correct, total = 0, 0\n",
    "        #k_Net.eval()\n",
    "        my_extended_model.eval()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"``Starting mini Testing``\")\n",
    "        with torch.no_grad():\n",
    "            #running_loss = 0.0\n",
    "            #loss_values = [] \n",
    "\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, test_data in enumerate(test_dataloader, 0):\n",
    "            # Get inputs\n",
    "                test_inputs = test_data[0].view(-1,3,105,600)\n",
    "                test_targets = test_data[1]\n",
    "                test_inputs = test_inputs.float()\n",
    "\n",
    "                test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "            # Generate outputs\n",
    "                test_outputs = my_extended_model(test_inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "\n",
    "                _, predicted = torch.max(test_outputs.data, 1)\n",
    "                total += test_targets.size(0)\n",
    "                #running_loss =+ loss.item() * batchSize\n",
    "                #correct += (predicted == targets).sum().item()\n",
    "                cntr = 0\n",
    "\n",
    "                for i in predicted:\n",
    "\n",
    "                    if i == test_targets[cntr]:\n",
    "                        correct += 1\n",
    "                    cntr += 1\n",
    "\n",
    "                #loss_values.append(running_loss / len(test_data))\n",
    "\n",
    "        print(\"Accuracy: \", 100*(correct/total))\n",
    "        print(\"\\n\")\n",
    "        my_extended_model.train()\n",
    "\n",
    "        \n",
    "\n",
    "        #running_loss =+ loss.item() * batchSize\n",
    "        #loss_values.append(running_loss / len(training_data))\n",
    "    if print_flag == True:\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss} \\n\")\n",
    "    else:\n",
    "        print_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "correct, total = 0, 0\n",
    "batchSize = 32\n",
    "test_data = key_training_data[-val_size:]\n",
    "test_dataloader = DataLoader(test_data, batch_size = batchSize, shuffle=True, drop_last=True)\n",
    "\n",
    "#k_Net.eval()\n",
    "my_extended_model.eval()\n",
    "\n",
    "print(\"``````Starting Testing``````\")\n",
    "with torch.no_grad():\n",
    "    #running_loss = 0.0\n",
    "    #loss_values = [] \n",
    "\n",
    "    # Iterate over the test data and generate predictions\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "    # Get inputs\n",
    "        inputs = data[0].view(-1,3,105,600)\n",
    "        targets = data[1]\n",
    "        inputs = inputs.float()\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "    # Generate outputs\n",
    "        outputs = my_extended_model(inputs)\n",
    "\n",
    "    # Set total and correct\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        #running_loss =+ loss.item() * batchSize\n",
    "        #correct += (predicted == targets).sum().item()\n",
    "        cntr = 0\n",
    "        \n",
    "        for i in predicted:\n",
    "\n",
    "            if i == targets[cntr]:\n",
    "                correct += 1\n",
    "            cntr += 1\n",
    "\n",
    "        #loss_values.append(running_loss / len(test_data))\n",
    "    \n",
    "print(\"Accuracy: \", 100*(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct)\n",
    "print(total)\n",
    "print(len(key_training_data))\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
